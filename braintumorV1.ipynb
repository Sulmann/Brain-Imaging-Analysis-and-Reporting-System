{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Brain Imaging Analysis and Reporting System"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-10-21 19:43:57.688604: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras.applications import VGG16, EfficientNetB0, MobileNetV2\n",
    "from tensorflow.keras.models import Model, load_model\n",
    "from tensorflow.keras.layers import Flatten, Dense, Dropout\n",
    "import numpy as np\n",
    "import os\n",
    "import cv2\n",
    "from sklearn.model_selection import train_test_split\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import confusion_matrix, classification_report, ConfusionMatrixDisplay, precision_score, recall_score, f1_score\n",
    "from PIL import Image\n",
    "from ultralytics import YOLO\n",
    "from fpdf import FPDF\n",
    "\n",
    "# YOLO model\n",
    "yolo_model = YOLO('yolov8n.pt')\n",
    "\n",
    "def load_and_preprocess_images(directory, target_size=(224, 224)):\n",
    "    X, y = [], []\n",
    "    class_folders = os.listdir(directory)\n",
    "    class_folders.sort()\n",
    "\n",
    "    for class_index, class_folder in enumerate(class_folders):\n",
    "        class_path = os.path.join(directory, class_folder)\n",
    "        if os.path.isdir(class_path):\n",
    "            for image_file in os.listdir(class_path):\n",
    "                image_path = os.path.join(class_path, image_file)\n",
    "                try:\n",
    "                    image = cv2.imread(image_path)\n",
    "                    image = cv2.resize(image, target_size)\n",
    "                    X.append(image)\n",
    "                    y.append(class_index)\n",
    "                except Exception as e:\n",
    "                    print(f\"Error loading {image_path}: {e}\")\n",
    "    \n",
    "    X = np.array(X)\n",
    "    y = np.array(y)\n",
    "    return X, y\n",
    "\n",
    "# Load and preprocess images\n",
    "path = \"archive/Training\"\n",
    "X, y = load_and_preprocess_images(path)\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Function to create a simple CNN model\n",
    "def create_cnn(input_shape, num_classes):\n",
    "    inputs = tf.keras.Input(shape=input_shape)\n",
    "    x = tf.keras.layers.Conv2D(32, (3, 3), activation='relu')(inputs)\n",
    "    x = tf.keras.layers.MaxPooling2D((2, 2))(x)\n",
    "    x = tf.keras.layers.Conv2D(64, (3, 3), activation='relu')(x)\n",
    "    x = tf.keras.layers.MaxPooling2D((2, 2))(x)\n",
    "    x = tf.keras.layers.Flatten()(x)\n",
    "    x = tf.keras.layers.Dense(128, activation='relu')(x)\n",
    "    x = tf.keras.layers.Dropout(0.5)(x)\n",
    "    outputs = tf.keras.layers.Dense(num_classes, activation='softmax')(x)\n",
    "    model = Model(inputs, outputs)\n",
    "    return model\n",
    "\n",
    "# Function to create and train a model (VGG16, EfficientNet, MobileNet)\n",
    "def train_model(base_model, X_train, y_train, X_test, y_test, num_classes):\n",
    "    base_model.trainable = False\n",
    "    x = Flatten()(base_model.output)\n",
    "    x = Dense(128, activation='relu')(x)\n",
    "    x = Dropout(0.5)(x)\n",
    "    predictions = Dense(num_classes, activation='softmax')(x)\n",
    "    model = Model(inputs=base_model.input, outputs=predictions)\n",
    "\n",
    "    model.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
    "    model.fit(X_train, y_train, epochs=7, validation_data=(X_test, y_test))\n",
    "    return model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/7\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-10-21 19:44:06.835266: W external/local_tsl/tsl/framework/cpu_allocator_impl.cc:83] Allocation of 687762432 exceeds 10% of free system memory.\n",
      "2024-10-21 19:44:07.940551: W external/local_tsl/tsl/framework/cpu_allocator_impl.cc:83] Allocation of 411041792 exceeds 10% of free system memory.\n",
      "2024-10-21 19:44:08.065497: W external/local_tsl/tsl/framework/cpu_allocator_impl.cc:83] Allocation of 411041792 exceeds 10% of free system memory.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\r",
      "\u001b[1m  1/143\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m7:59\u001b[0m 3s/step - accuracy: 0.2812 - loss: 13.8252"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-10-21 19:44:10.562796: W external/local_tsl/tsl/framework/cpu_allocator_impl.cc:83] Allocation of 411041792 exceeds 10% of free system memory.\n",
      "2024-10-21 19:44:10.684788: W external/local_tsl/tsl/framework/cpu_allocator_impl.cc:83] Allocation of 411041792 exceeds 10% of free system memory.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m143/143\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m515s\u001b[0m 4s/step - accuracy: 0.6785 - loss: 5.8477 - val_accuracy: 0.8661 - val_loss: 0.4227\n",
      "Epoch 2/7\n",
      "\u001b[1m143/143\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m524s\u001b[0m 4s/step - accuracy: 0.8085 - loss: 0.5486 - val_accuracy: 0.8924 - val_loss: 0.3756\n",
      "Epoch 3/7\n",
      "\u001b[1m143/143\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m557s\u001b[0m 4s/step - accuracy: 0.8356 - loss: 0.4582 - val_accuracy: 0.9204 - val_loss: 0.2979\n",
      "Epoch 4/7\n",
      "\u001b[1m143/143\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m542s\u001b[0m 4s/step - accuracy: 0.8493 - loss: 0.3951 - val_accuracy: 0.9125 - val_loss: 0.3069\n",
      "Epoch 5/7\n",
      "\u001b[1m143/143\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m518s\u001b[0m 4s/step - accuracy: 0.8595 - loss: 0.3939 - val_accuracy: 0.9274 - val_loss: 0.2411\n",
      "Epoch 6/7\n",
      "\u001b[1m143/143\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m503s\u001b[0m 4s/step - accuracy: 0.8812 - loss: 0.3313 - val_accuracy: 0.9169 - val_loss: 0.2833\n",
      "Epoch 7/7\n",
      "\u001b[1m143/143\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m506s\u001b[0m 4s/step - accuracy: 0.8825 - loss: 0.3402 - val_accuracy: 0.9160 - val_loss: 0.3571\n"
     ]
    }
   ],
   "source": [
    "# Train VGG16 model\n",
    "vgg16_model = VGG16(weights='imagenet', include_top=False, input_shape=(224, 224, 3))\n",
    "vgg16_model_final = train_model(vgg16_model, X_train, y_train, X_test, y_test, len(os.listdir(path)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train EfficientNet model\n",
    "efficientnet_model = EfficientNetB0(weights='imagenet', include_top=False, input_shape=(224, 224, 3))\n",
    "efficientnet_model_final = train_model(efficientnet_model, X_train, y_train, X_test, y_test, len(os.listdir(path)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train MobileNet model\n",
    "mobilenet_model = MobileNetV2(weights='imagenet', include_top=False, input_shape=(224, 224, 3))\n",
    "mobilenet_model_final = train_model(mobilenet_model, X_train, y_train, X_test, y_test, len(os.listdir(path)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m99s\u001b[0m 3s/step - accuracy: 0.9082 - loss: 0.3481\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.3570597469806671, 0.9160104990005493]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Evaluate the CNN models\n",
    "vgg16_model_final.evaluate(X_test, y_test)\n",
    "#efficientnet_model_final.evaluate(X_test, y_test)\n",
    "#mobilenet_model_final.evaluate(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to preprocess image\n",
    "def preprocess_image(image):\n",
    "    image = image.resize((224, 224))  # Resize to match model input\n",
    "    image = np.array(image)\n",
    "    image = image / 255.0  # Normalize pixel values\n",
    "    image = np.expand_dims(image, axis=0)  # Add batch dimension\n",
    "    return image\n",
    "\n",
    "# Function to predict tumor presence using CNN\n",
    "def predict_tumor(image, model):\n",
    "    processed_image = preprocess_image(image)\n",
    "    prediction = model.predict(processed_image)\n",
    "    predicted_class = np.argmax(prediction, axis=1)\n",
    "    return \"Tumor Detected\" if predicted_class == 1 else \"No Tumor\"\n",
    "\n",
    "# Function to detect tumor using YOLO and draw bounding box\n",
    "def detect_and_draw_bounding_box(image_path):\n",
    "    results = yolo_model.predict(image_path, save=False, show=False)\n",
    "    image = cv2.imread(image_path)\n",
    "    boxes = results[0].boxes\n",
    "\n",
    "    if boxes:  # Check if any boxes are detected\n",
    "        for box in boxes:\n",
    "            x1, y1, x2, y2 = box.xyxy[0].numpy().astype(int)\n",
    "            cv2.rectangle(image, (x1, y1), (x2, y2), (0, 255, 0), 2)\n",
    "        return image, True  # Return the image with bounding box and detection status\n",
    "    else:\n",
    "        return image, False\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to handle user image input\n",
    "def handle_user_image_input(image_path, model):\n",
    "    try:\n",
    "        image = Image.open(image_path)\n",
    "        result = predict_tumor(image, model)\n",
    "        print(f\"Prediction: {result}\")\n",
    "        \n",
    "        if result == \"Tumor Detected\":\n",
    "            image_with_box, tumor_detected = detect_and_draw_bounding_box(image_path)\n",
    "            return result, image_with_box if tumor_detected else None\n",
    "        else:\n",
    "            return result, None\n",
    "    except Exception as e:\n",
    "        print(f\"Error processing image: {e}\")\n",
    "        return None, None\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to generate a PDF report\n",
    "def generate_pdf_report(image_path, prediction, image_with_box=None):\n",
    "    pdf = FPDF()\n",
    "    pdf.add_page()\n",
    "    \n",
    "    pdf.set_font(\"Arial\", size=16)\n",
    "    pdf.cell(200, 10, txt=\"Brain Tumor Detection Report\", ln=True, align=\"C\")\n",
    "\n",
    "    pdf.set_font(\"Arial\", size=12)\n",
    "    pdf.cell(200, 10, txt=f\"Prediction: {prediction}\", ln=True, align=\"L\")\n",
    "\n",
    "    if prediction == \"Tumor Detected\" and image_with_box is not None:\n",
    "        output_image_path = \"output_image_with_box.jpg\"\n",
    "        cv2.imwrite(output_image_path, image_with_box)\n",
    "        pdf.image(output_image_path, x=10, y=30, w=100)\n",
    "    else:\n",
    "        pdf.image(image_path, x=10, y=30, w=100)\n",
    "    \n",
    "    output_path = \"tumor_detection_report.pdf\"\n",
    "    pdf.output(output_path)\n",
    "    print(f\"PDF report generated: {output_path}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 104ms/step\n",
      "Prediction: Tumor Detected\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Example usage\n",
    "image_path = \"Te-me_0027.jpg\"  # Replace with actual image path\n",
    "prediction, image_with_box = handle_user_image_input(image_path, vgg16_model_final)\n",
    "if prediction:\n",
    "    generate_pdf_report(image_path, prediction, image_with_box)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'vgg16_model_final' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_36244/571617141.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# Generate confusion matrix and classification report\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0my_pred\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mvgg16_model_final\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_test\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0my_pred_classes\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0margmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_pred\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;31m# Use class names instead of numbers in confusion matrix and classification report\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'vgg16_model_final' is not defined"
     ]
    }
   ],
   "source": [
    "# Generate confusion matrix and classification report\n",
    "y_pred = vgg16_model_final.predict(X_test)\n",
    "y_pred_classes = np.argmax(y_pred, axis=1)\n",
    "\n",
    "# Use class names instead of numbers in confusion matrix and classification report\n",
    "class_names = os.listdir(path)  # Get class names from directory\n",
    "cm = confusion_matrix(y_test, y_pred_classes)\n",
    "\n",
    "# Plot confusion matrix with class names\n",
    "ConfusionMatrixDisplay(confusion_matrix=cm, display_labels=class_names).plot(cmap='Blues')\n",
    "plt.title(\"Confusion Matrix\")\n",
    "plt.show()\n",
    "\n",
    "# Generate classification report using class names\n",
    "report = classification_report(y_test, y_pred_classes, target_names=class_names)\n",
    "print(report)\n",
    "\n",
    "with open(\"classification_report.txt\", \"w\") as f:\n",
    "    f.write(report)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate precision, recall, and F1 score\n",
    "precision = precision_score(y_test, y_pred_classes, average='weighted')\n",
    "recall = recall_score(y_test, y_pred_classes, average='weighted')\n",
    "f1 = f1_score(y_test, y_pred_classes, average='weighted')\n",
    "\n",
    "print(f\"Precision: {precision:.2f}\")\n",
    "print(f\"Recall: {recall:.2f}\")\n",
    "print(f\"F1 Score: {f1:.2f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 92ms/step\n",
      "Prediction: No Tumor\n",
      "PDF report generated: tumor_detection_report.pdf\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m105s\u001b[0m 3s/step\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "      glioma       0.91      0.90      0.90       288\n",
      "  meningioma       0.85      0.81      0.83       265\n",
      "     notumor       0.97      0.97      0.97       291\n",
      "   pituitary       0.93      0.98      0.95       299\n",
      "\n",
      "    accuracy                           0.92      1143\n",
      "   macro avg       0.91      0.91      0.91      1143\n",
      "weighted avg       0.92      0.92      0.92      1143\n",
      "\n",
      "Precision: 0.92\n",
      "Recall: 0.92\n",
      "F1 Score: 0.92\n",
      "\u001b[1m143/143\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m436s\u001b[0m 3s/step - accuracy: 0.9641 - loss: 0.1314\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m125s\u001b[0m 3s/step - accuracy: 0.9082 - loss: 0.3481\n",
      "Training Loss: 0.1246\n",
      "Training Accuracy: 96.32%\n",
      "Validation Loss: 0.3571\n",
      "Validation Accuracy: 91.60%\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "# Calculate precision, recall, and F1 score for each class\n",
    "precision = precision_score(y_test, y_pred_classes, average='weighted')\n",
    "recall = recall_score(y_test, y_pred_classes, average='weighted')\n",
    "f1 = f1_score(y_test, y_pred_classes, average='weighted')\n",
    "\n",
    "print(f\"Precision: {precision:.2f}\")\n",
    "print(f\"Recall: {recall:.2f}\")\n",
    "print(f\"F1 Score: {f1:.2f}\")\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate and display overall accuracy and loss for training and validation\n",
    "train_loss, train_accuracy = vgg16_model_final.evaluate(X_train, y_train)\n",
    "val_loss, val_accuracy = vgg16_model_final.evaluate(X_test, y_test)\n",
    "\n",
    "print(f\"Training Loss: {train_loss:.4f}\")\n",
    "print(f\"Training Accuracy: {train_accuracy * 100:.2f}%\")\n",
    "print(f\"Validation Loss: {val_loss:.4f}\")\n",
    "print(f\"Validation Accuracy: {val_accuracy * 100:.2f}%\")"
   ]
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "nvidiaTeslaT4",
   "dataSources": [
    {
     "datasetId": 1608934,
     "sourceId": 2645886,
     "sourceType": "datasetVersion"
    },
    {
     "datasetId": 2020131,
     "sourceId": 3347069,
     "sourceType": "datasetVersion"
    },
    {
     "datasetId": 2576496,
     "sourceId": 4436411,
     "sourceType": "datasetVersion"
    },
    {
     "datasetId": 2639673,
     "sourceId": 4542090,
     "sourceType": "datasetVersion"
    }
   ],
   "dockerImageVersionId": 30665,
   "isGpuEnabled": true,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
